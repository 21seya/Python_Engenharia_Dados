{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"nome\": \"Joao\",\n",
      "    \"idade\": 30,\n",
      "    \"cidade\": \"Sao Paulo\",\n",
      "    \"habilidades\": [\n",
      "        \"Python\",\n",
      "        \"JavaScript\",\n",
      "        \"SQL\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Criando um dicionário\n",
    "data = {\n",
    "    \"nome\": \"Joao\",\n",
    "    \"idade\": 30,\n",
    "    \"cidade\": \"Sao Paulo\",\n",
    "    \"habilidades\": [\"Python\", \"JavaScript\", \"SQL\"]\n",
    "}\n",
    "\n",
    "# Convertendo o dicionário para JSON\n",
    "json_data = json.dumps(data, indent=4)\n",
    "\n",
    "# Exibindo o JSON\n",
    "print(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rodrigo': {'CPF': '222.222.333-47', 'Sexo': 'Masculino', 'Endereco': 'Rua maranhoes', 'Idade': 34}, 'Ferando': {'CPF': '111.333.444-47', 'Sexo': 'Masculino', 'Endereco': 'Rua souza', 'Idade': 30}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Supondo que temos um arquivo 'dados.json' com um conteúdo JSON\n",
    "with open('exemplo.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Exibindo os dados lidos\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"empresa\": \"TechCorp\",\n",
      "    \"funcionarios\": [\n",
      "        {\n",
      "            \"nome\": \"Carlos\",\n",
      "            \"cargo\": \"Desenvolvedor\",\n",
      "            \"salario\": 5000\n",
      "        },\n",
      "        {\n",
      "            \"nome\": \"Maria\",\n",
      "            \"cargo\": \"Designer\",\n",
      "            \"salario\": 4500\n",
      "        }\n",
      "    ],\n",
      "    \"localizacao\": \"Sao Paulo\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Estrutura JSON mais complexa\n",
    "data = {\n",
    "    \"empresa\": \"TechCorp\",\n",
    "    \"funcionarios\": [\n",
    "        {\n",
    "            \"nome\": \"Carlos\",\n",
    "            \"cargo\": \"Desenvolvedor\",\n",
    "            \"salario\": 5000\n",
    "        },\n",
    "        {\n",
    "            \"nome\": \"Maria\",\n",
    "            \"cargo\": \"Designer\",\n",
    "            \"salario\": 4500\n",
    "        }\n",
    "    ],\n",
    "    \"localizacao\": \"Sao Paulo\"\n",
    "}\n",
    "\n",
    "# Convertendo para JSON\n",
    "json_data = json.dumps(data, indent=4)\n",
    "\n",
    "# Exibindo o JSON gerado\n",
    "print(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type set is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomes\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoão\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCarlos\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAna\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convertendo para JSON (set será convertido para lista)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m json_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Exibindo o JSON\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(json_data)\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:201\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type set is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dicionário com tipo de dado incompatível (set)\n",
    "data = {\n",
    "    \"nomes\": {\"João\", \"Carlos\", \"Ana\"}\n",
    "}\n",
    "\n",
    "# Convertendo para JSON (set será convertido para lista)\n",
    "json_data = json.dumps(data, indent=4)\n",
    "\n",
    "# Exibindo o JSON\n",
    "print(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"30\": [\n",
      "        {\n",
      "            \"nome\": \"Joao\",\n",
      "            \"idade\": 30,\n",
      "            \"cidade\": \"Sao Paulo\"\n",
      "        },\n",
      "        {\n",
      "            \"nome\": \"Carlos\",\n",
      "            \"idade\": 30,\n",
      "            \"cidade\": \"Sao Paulo\"\n",
      "        }\n",
      "    ],\n",
      "    \"25\": [\n",
      "        {\n",
      "            \"nome\": \"Maria\",\n",
      "            \"idade\": 25,\n",
      "            \"cidade\": \"Rio de Janeiro\"\n",
      "        },\n",
      "        {\n",
      "            \"nome\": \"Ana\",\n",
      "            \"idade\": 25,\n",
      "            \"cidade\": \"Belo Horizonte\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Exemplo de dados JSON de pessoas\n",
    "data = '''\n",
    "[\n",
    "    {\"nome\": \"Joao\", \"idade\": 30, \"cidade\": \"Sao Paulo\"},\n",
    "    {\"nome\": \"Maria\", \"idade\": 25, \"cidade\": \"Rio de Janeiro\"},\n",
    "    {\"nome\": \"Carlos\", \"idade\": 30, \"cidade\": \"Sao Paulo\"},\n",
    "    {\"nome\": \"Ana\", \"idade\": 25, \"cidade\": \"Belo Horizonte\"}\n",
    "]\n",
    "'''\n",
    "\n",
    "# Carregar o JSON em um objeto Python\n",
    "pessoas = json.loads(data)\n",
    "\n",
    "# Agrupar pessoas pela idade\n",
    "grupo_por_idade = defaultdict(list)\n",
    "for pessoa in pessoas:\n",
    "    grupo_por_idade[pessoa['idade']].append(pessoa)\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(json.dumps(grupo_por_idade, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"nome\": \"Notebook\",\n",
      "        \"preco\": 3000,\n",
      "        \"categoria\": \"Eletronicos\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Smartphone\",\n",
      "        \"preco\": 1500,\n",
      "        \"categoria\": \"Eletronicos\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Cadeira gamer\",\n",
      "        \"preco\": 1200,\n",
      "        \"categoria\": \"Moveis\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de produtos\n",
    "data = '''\n",
    "{\n",
    "    \"produtos\": [\n",
    "        {\"nome\": \"Notebook\", \"preco\": 3000, \"categoria\": \"Eletronicos\"},\n",
    "        {\"nome\": \"Smartphone\", \"preco\": 1500, \"categoria\": \"Eletronicos\"},\n",
    "        {\"nome\": \"Fones de ouvido\", \"preco\": 200, \"categoria\": \"Acessórios\"},\n",
    "        {\"nome\": \"Cadeira gamer\", \"preco\": 1200, \"categoria\": \"Moveis\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "produtos = json.loads(data)\n",
    "\n",
    "# Filtrando produtos com preço superior a 1000\n",
    "produtos_filtrados = [produto for produto in produtos['produtos'] if produto['preco'] > 1000]\n",
    "\n",
    "# Exibindo os produtos filtrados\n",
    "print(json.dumps(produtos_filtrados, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"usuario\": {\n",
      "        \"nome\": \"Ricardo\",\n",
      "        \"idade\": 28,\n",
      "        \"cidade\": \"Sao Paulo\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de um usuário\n",
    "data = '''\n",
    "{\n",
    "    \"usuario\": {\n",
    "        \"nome\": \"Ricardo\",\n",
    "        \"idade\": 28,\n",
    "        \"cidade\": \"Curitiba\"\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar o JSON\n",
    "usuario = json.loads(data)\n",
    "\n",
    "# Atualizando a cidade do usuário\n",
    "usuario['usuario']['cidade'] = \"Sao Paulo\"\n",
    "\n",
    "# Exibindo o JSON atualizado\n",
    "print(json.dumps(usuario, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"cliente_id\": 1,\n",
      "        \"produto\": \"Notebook\",\n",
      "        \"quantidade\": 1,\n",
      "        \"cliente_nome\": \"Lucas\",\n",
      "        \"cliente_email\": \"lucas@email.com\"\n",
      "    },\n",
      "    {\n",
      "        \"cliente_id\": 2,\n",
      "        \"produto\": \"Smartphone\",\n",
      "        \"quantidade\": 2,\n",
      "        \"cliente_nome\": \"Maria\",\n",
      "        \"cliente_email\": \"maria@email.com\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de clientes\n",
    "clientes_data = '''\n",
    "{\n",
    "    \"clientes\": [\n",
    "        {\"id\": 1, \"nome\": \"Lucas\", \"email\": \"lucas@email.com\"},\n",
    "        {\"id\": 2, \"nome\": \"Maria\", \"email\": \"maria@email.com\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Dados JSON de pedidos\n",
    "pedidos_data = '''\n",
    "{\n",
    "    \"pedidos\": [\n",
    "        {\"cliente_id\": 1, \"produto\": \"Notebook\", \"quantidade\": 1},\n",
    "        {\"cliente_id\": 2, \"produto\": \"Smartphone\", \"quantidade\": 2}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados\n",
    "clientes = json.loads(clientes_data)\n",
    "pedidos = json.loads(pedidos_data)\n",
    "\n",
    "# Mesclando os dados de clientes com os pedidos\n",
    "for pedido in pedidos['pedidos']:\n",
    "    for cliente in clientes['clientes']:\n",
    "        if cliente['id'] == pedido['cliente_id']:\n",
    "            pedido['cliente_nome'] = cliente['nome']\n",
    "            pedido['cliente_email'] = cliente['email']\n",
    "\n",
    "# Exibindo os pedidos com informações completas\n",
    "print(json.dumps(pedidos['pedidos'], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON válido!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "# Exemplo de esquema JSON esperado\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"nome\": {\"type\": \"string\"},\n",
    "        \"idade\": {\"type\": \"integer\"},\n",
    "        \"cidade\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"nome\", \"idade\", \"cidade\"]\n",
    "}\n",
    "\n",
    "# Dados JSON a serem validados\n",
    "data = '''\n",
    "{\n",
    "    \"nome\": \"Carlos\",\n",
    "    \"idade\": 30,\n",
    "    \"cidade\": \"Rio de Janeiro\"\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "user_data = json.loads(data)\n",
    "\n",
    "# Validando os dados com o esquema\n",
    "try:\n",
    "    validate(instance=user_data, schema=schema)\n",
    "    print(\"JSON válido!\")\n",
    "except ValidationError as e:\n",
    "    print(f\"Erro na validação: {e.message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"nome\": \"Fones de ouvido\",\n",
      "        \"preco\": 200,\n",
      "        \"categoria\": \"Acessorios\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Cadeira gamer\",\n",
      "        \"preco\": 1200,\n",
      "        \"categoria\": \"Moveis\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Smartphone\",\n",
      "        \"preco\": 1500,\n",
      "        \"categoria\": \"Eletronicos\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Notebook\",\n",
      "        \"preco\": 3000,\n",
      "        \"categoria\": \"Eletronicos\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de produtos\n",
    "data = '''\n",
    "{\n",
    "    \"produtos\": [\n",
    "        {\"nome\": \"Notebook\", \"preco\": 3000, \"categoria\": \"Eletronicos\"},\n",
    "        {\"nome\": \"Smartphone\", \"preco\": 1500, \"categoria\": \"Eletronicos\"},\n",
    "        {\"nome\": \"Fones de ouvido\", \"preco\": 200, \"categoria\": \"Acessorios\"},\n",
    "        {\"nome\": \"Cadeira gamer\", \"preco\": 1200, \"categoria\": \"Moveis\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "produtos = json.loads(data)\n",
    "\n",
    "# Ordenando os produtos pelo preço de forma crescente\n",
    "produtos_ordenados = sorted(produtos['produtos'], key=lambda x: x['preco'])\n",
    "\n",
    "# Exibindo os produtos ordenados\n",
    "print(json.dumps(produtos_ordenados, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Notebook\": 2,\n",
      "    \"Smartphone\": 2,\n",
      "    \"Cadeira gamer\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Dados JSON de vendas\n",
    "data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"produto\": \"Notebook\", \"quantidade\": 1},\n",
    "        {\"produto\": \"Smartphone\", \"quantidade\": 2},\n",
    "        {\"produto\": \"Notebook\", \"quantidade\": 3},\n",
    "        {\"produto\": \"Smartphone\", \"quantidade\": 1},\n",
    "        {\"produto\": \"Cadeira gamer\", \"quantidade\": 2}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "vendas = json.loads(data)\n",
    "\n",
    "# Contando as ocorrências de cada produto\n",
    "contador_produtos = Counter([venda['produto'] for venda in vendas['vendas']])\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(json.dumps(contador_produtos, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Notebook\": 4,\n",
      "    \"Smartphone\": 3,\n",
      "    \"Cadeira gamer\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dados JSON de vendas\n",
    "data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"produto\": \"Notebook\", \"quantidade\": 1},\n",
    "        {\"produto\": \"Smartphone\", \"quantidade\": 2},\n",
    "        {\"produto\": \"Notebook\", \"quantidade\": 3},\n",
    "        {\"produto\": \"Smartphone\", \"quantidade\": 1},\n",
    "        {\"produto\": \"Cadeira gamer\", \"quantidade\": 2}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "vendas = json.loads(data)\n",
    "\n",
    "# Agregando as vendas por produto e somando as quantidades\n",
    "total_vendas = defaultdict(int)\n",
    "for venda in vendas['vendas']:\n",
    "    total_vendas[venda['produto']] += venda['quantidade']\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(json.dumps(total_vendas, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"nome\": \"Notebook\",\n",
      "        \"preco\": 3300.0000000000005,\n",
      "        \"categoria\": \"Eletronicos\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Smartphone\",\n",
      "        \"preco\": 1650.0000000000002,\n",
      "        \"categoria\": \"Eletronicos\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Fones de ouvido\",\n",
      "        \"preco\": 200,\n",
      "        \"categoria\": \"Acessorios\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Cadeira gamer\",\n",
      "        \"preco\": 1200,\n",
      "        \"categoria\": \"Moveis\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de produtos\n",
    "data = '''\n",
    "{\n",
    "    \"produtos\": [\n",
    "        {\"nome\": \"Notebook\", \"preco\": 3000, \"categoria\": \"Eletronicos\"},\n",
    "        {\"nome\": \"Smartphone\", \"preco\": 1500, \"categoria\": \"Eletronicos\"},\n",
    "        {\"nome\": \"Fones de ouvido\", \"preco\": 200, \"categoria\": \"Acessorios\"},\n",
    "        {\"nome\": \"Cadeira gamer\", \"preco\": 1200, \"categoria\": \"Moveis\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "produtos = json.loads(data)\n",
    "\n",
    "# Atualizando o preço de todos os produtos na categoria 'Eletrônicos'\n",
    "for produto in produtos['produtos']:\n",
    "    if produto['categoria'] == 'Eletronicos':\n",
    "        produto['preco'] *= 1.10  # Aumento de 10% no preço\n",
    "\n",
    "# Exibindo os produtos com os preços atualizados\n",
    "print(json.dumps(produtos['produtos'], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"nome\": \"Carlos\",\n",
      "        \"idade\": 35,\n",
      "        \"cidade\": \"Sao Paulo\"\n",
      "    },\n",
      "    {\n",
      "        \"nome\": \"Pedro\",\n",
      "        \"idade\": 40,\n",
      "        \"cidade\": \"Sao Paulo\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de pessoas\n",
    "data = '''\n",
    "{\n",
    "    \"pessoas\": [\n",
    "        {\"nome\": \"João\", \"idade\": 30, \"cidade\": \"Sao Paulo\"},\n",
    "        {\"nome\": \"Maria\", \"idade\": 25, \"cidade\": \"Rio de Janeiro\"},\n",
    "        {\"nome\": \"Carlos\", \"idade\": 35, \"cidade\": \"Sao Paulo\"},\n",
    "        {\"nome\": \"Ana\", \"idade\": 28, \"cidade\": \"Belo Horizonte\"},\n",
    "        {\"nome\": \"Pedro\", \"idade\": 40, \"cidade\": \"Sao Paulo\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "pessoas = json.loads(data)\n",
    "\n",
    "# Buscando pessoas com idade maior que 30\n",
    "pessoas_maiores_30 = [pessoa for pessoa in pessoas['pessoas'] if pessoa['idade'] > 30]\n",
    "\n",
    "# Exibindo as pessoas que atendem ao critério\n",
    "print(json.dumps(pessoas_maiores_30, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"cliente_id\": 1,\n",
      "        \"produto\": \"Notebook\",\n",
      "        \"quantidade\": 1,\n",
      "        \"cliente_nome\": \"Lucas\",\n",
      "        \"cliente_email\": \"lucas@email.com\"\n",
      "    },\n",
      "    {\n",
      "        \"cliente_id\": 2,\n",
      "        \"produto\": \"Smartphone\",\n",
      "        \"quantidade\": 2,\n",
      "        \"cliente_nome\": \"Maria\",\n",
      "        \"cliente_email\": \"maria@email.com\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de clientes\n",
    "clientes_data = '''\n",
    "{\n",
    "    \"clientes\": [\n",
    "        {\"id\": 1, \"nome\": \"Lucas\", \"email\": \"lucas@email.com\"},\n",
    "        {\"id\": 2, \"nome\": \"Maria\", \"email\": \"maria@email.com\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Dados JSON de compras\n",
    "compras_data = '''\n",
    "{\n",
    "    \"compras\": [\n",
    "        {\"cliente_id\": 1, \"produto\": \"Notebook\", \"quantidade\": 1},\n",
    "        {\"cliente_id\": 2, \"produto\": \"Smartphone\", \"quantidade\": 2}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "clientes = json.loads(clientes_data)\n",
    "compras = json.loads(compras_data)\n",
    "\n",
    "# Mesclando os dados de clientes com suas compras\n",
    "for compra in compras['compras']:\n",
    "    for cliente in clientes['clientes']:\n",
    "        if cliente['id'] == compra['cliente_id']:\n",
    "            compra['cliente_nome'] = cliente['nome']\n",
    "            compra['cliente_email'] = cliente['email']\n",
    "\n",
    "# Exibindo as compras com as informações dos clientes\n",
    "print(json.dumps(compras['compras'], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Alimentacao\": 200.8,\n",
      "    \"Transporte\": 80.75,\n",
      "    \"Saude\": 200.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dados JSON de transações financeiras\n",
    "data = '''\n",
    "{\n",
    "    \"transacoes\": [\n",
    "        {\"categoria\": \"Alimentacao\", \"valor\": 120.50, \"data\": \"2025-01-01\"},\n",
    "        {\"categoria\": \"Transporte\", \"valor\": 50.75, \"data\": \"2025-01-02\"},\n",
    "        {\"categoria\": \"Alimentacao\", \"valor\": 80.30, \"data\": \"2025-01-03\"},\n",
    "        {\"categoria\": \"Saude\", \"valor\": 200.00, \"data\": \"2025-01-04\"},\n",
    "        {\"categoria\": \"Transporte\", \"valor\": 30.00, \"data\": \"2025-01-05\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "transacoes = json.loads(data)\n",
    "\n",
    "# Agregando os valores das transações por categoria\n",
    "gastos_por_categoria = defaultdict(float)\n",
    "for transacao in transacoes['transacoes']:\n",
    "    gastos_por_categoria[transacao['categoria']] += transacao['valor']\n",
    "\n",
    "# Exibindo os gastos por categoria\n",
    "print(json.dumps(gastos_por_categoria, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"nome\": \"Carlos\",\n",
      "        \"idade\": 40,\n",
      "        \"cidade\": \"Rio de Janeiro\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de usuários\n",
    "data = '''\n",
    "{\n",
    "    \"usuarios\": [\n",
    "        {\"nome\": \"João\", \"idade\": 28, \"cidade\": \"Sao Paulo\"},\n",
    "        {\"nome\": \"Maria\", \"idade\": 35, \"cidade\": \"Rio de Janeiro\"},\n",
    "        {\"nome\": \"Carlos\", \"idade\": 40, \"cidade\": \"Sao Paulo\"},\n",
    "        {\"nome\": \"Ana\", \"idade\": 25, \"cidade\": \"Belo Horizonte\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "usuarios = json.loads(data)\n",
    "\n",
    "# Filtrando usuários com idade superior a 30 e cidade São Paulo\n",
    "usuarios_filtrados = [\n",
    "    usuario for usuario in usuarios['usuarios'] \n",
    "    if usuario['idade'] > 30 and usuario['cidade'] == \"Sao Paulo\"\n",
    "]\n",
    "\n",
    "# Atualizando a cidade dos usuários filtrados\n",
    "for usuario in usuarios_filtrados:\n",
    "    usuario['cidade'] = \"Rio de Janeiro\"  # Mudando cidade para todos os usuários filtrados\n",
    "\n",
    "# Exibindo os usuários filtrados e atualizados\n",
    "print(json.dumps(usuarios_filtrados, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": 1,\n",
      "        \"nome\": \"Notebook\",\n",
      "        \"estoque\": 5,\n",
      "        \"preco\": 3000\n",
      "    },\n",
      "    {\n",
      "        \"id\": 2,\n",
      "        \"nome\": \"Smartphone\",\n",
      "        \"estoque\": 3,\n",
      "        \"preco\": 1500\n",
      "    },\n",
      "    {\n",
      "        \"id\": 3,\n",
      "        \"nome\": \"Fones de ouvido\",\n",
      "        \"estoque\": 8,\n",
      "        \"preco\": 200\n",
      "    },\n",
      "    {\n",
      "        \"id\": 4,\n",
      "        \"nome\": \"Cadeira gamer\",\n",
      "        \"estoque\": 3,\n",
      "        \"preco\": 1200\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de inventário\n",
    "data = '''\n",
    "{\n",
    "    \"produtos\": [\n",
    "        {\"id\": 1, \"nome\": \"Notebook\", \"estoque\": 5, \"preco\": 3000},\n",
    "        {\"id\": 2, \"nome\": \"Smartphone\", \"estoque\": 2, \"preco\": 1500},\n",
    "        {\"id\": 3, \"nome\": \"Fones de ouvido\", \"estoque\": 8, \"preco\": 200},\n",
    "        {\"id\": 4, \"nome\": \"Cadeira gamer\", \"estoque\": 1, \"preco\": 1200}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "inventario = json.loads(data)\n",
    "\n",
    "# Definindo o limite mínimo de estoque\n",
    "estoque_minimo = 3\n",
    "\n",
    "# Verificando e reabastecendo produtos abaixo do estoque mínimo\n",
    "for produto in inventario['produtos']:\n",
    "    if produto['estoque'] < estoque_minimo:\n",
    "        produto['estoque'] = estoque_minimo  # Reabastecendo para o nível mínimo\n",
    "\n",
    "# Exibindo o inventário atualizado\n",
    "print(json.dumps(inventario['produtos'], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": 1,\n",
      "        \"nome\": \"Joao\",\n",
      "        \"email\": \"joao@email.com\",\n",
      "        \"compras\": [\n",
      "            {\n",
      "                \"usuario_id\": 1,\n",
      "                \"produto\": \"Notebook\",\n",
      "                \"quantidade\": 1\n",
      "            },\n",
      "            {\n",
      "                \"usuario_id\": 1,\n",
      "                \"produto\": \"Fones de ouvido\",\n",
      "                \"quantidade\": 3\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": 2,\n",
      "        \"nome\": \"Maria\",\n",
      "        \"email\": \"maria@email.com\",\n",
      "        \"compras\": [\n",
      "            {\n",
      "                \"usuario_id\": 2,\n",
      "                \"produto\": \"Smartphone\",\n",
      "                \"quantidade\": 2\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dados JSON de usuários\n",
    "usuarios_data = '''\n",
    "{\n",
    "    \"usuarios\": [\n",
    "        {\"id\": 1, \"nome\": \"Joao\", \"email\": \"joao@email.com\"},\n",
    "        {\"id\": 2, \"nome\": \"Maria\", \"email\": \"maria@email.com\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Dados JSON de compras\n",
    "compras_data = '''\n",
    "{\n",
    "    \"compras\": [\n",
    "        {\"usuario_id\": 1, \"produto\": \"Notebook\", \"quantidade\": 1},\n",
    "        {\"usuario_id\": 2, \"produto\": \"Smartphone\", \"quantidade\": 2},\n",
    "        {\"usuario_id\": 1, \"produto\": \"Fones de ouvido\", \"quantidade\": 3}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Carregar os dados JSON\n",
    "usuarios = json.loads(usuarios_data)\n",
    "compras = json.loads(compras_data)\n",
    "\n",
    "# Criando um dicionário de compras por usuário\n",
    "compras_por_usuario = {}\n",
    "for compra in compras['compras']:\n",
    "    usuario_id = compra['usuario_id']\n",
    "    if usuario_id not in compras_por_usuario:\n",
    "        compras_por_usuario[usuario_id] = []\n",
    "    compras_por_usuario[usuario_id].append(compra)\n",
    "\n",
    "# Mesclando os dados de compras com os dados de usuários\n",
    "for usuario in usuarios['usuarios']:\n",
    "    usuario['compras'] = compras_por_usuario.get(usuario['id'], [])\n",
    "\n",
    "# Exibindo os dados mesclados\n",
    "print(json.dumps(usuarios['usuarios'], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            clientes\n",
      "0  [{'id': 1, 'nome': 'Joao', 'idade': 28, 'cidad...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def carregar_json_para_dataframe(json_data):\n",
    "    \"\"\"\n",
    "    Função para carregar dados JSON em um DataFrame do pandas.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para um DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Exibir as primeiras linhas do DataFrame\n",
    "    return df.head()\n",
    "\n",
    "# Exemplo de uso\n",
    "json_data = '''\n",
    "{\n",
    "    \"clientes\": [\n",
    "        {\"id\": 1, \"nome\": \"Joao\", \"idade\": 28, \"cidade\": \"São Paulo\"},\n",
    "        {\"id\": 2, \"nome\": \"Maria\", \"idade\": 35, \"cidade\": \"Rio de Janeiro\"},\n",
    "        {\"id\": 3, \"nome\": \"Carlos\", \"idade\": 40, \"cidade\": \"São Paulo\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "df = carregar_json_para_dataframe(json_data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'idade'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'idade'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_filtrado\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m \u001b[43mfiltrar_clientes_por_idade\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_filtrado)\n",
      "Cell \u001b[1;32mIn[53], line 22\u001b[0m, in \u001b[0;36mfiltrar_clientes_por_idade\u001b[1;34m(idade_minima)\u001b[0m\n\u001b[0;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(data)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Filtrar os dados com base na idade\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m idade_minima]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_filtrado\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'idade'"
     ]
    }
   ],
   "source": [
    "def filtrar_clientes_por_idade(idade_minima):\n",
    "    \"\"\"\n",
    "    Função para filtrar clientes com idade superior ao limite definido.\n",
    "    \"\"\"\n",
    "        # Exemplo de uso\n",
    "    json_data = '''\n",
    "    {\n",
    "        \"clientes\": [\n",
    "            {\"id\": 1, \"nome\": \"Joao\", \"idade\": 28},\n",
    "            {\"id\": 2, \"nome\": \"Maria\", \"idade\": 35},\n",
    "            {\"id\": 3, \"nome\": \"Carlos\", \"idade\": 40}\n",
    "        ]\n",
    "    }\n",
    "    '''\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para um DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Filtrar os dados com base na idade\n",
    "    df_filtrado = df[df['idade'] > idade_minima]\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "# Exemplo de uso\n",
    "df_filtrado = filtrar_clientes_por_idade(json_data)\n",
    "print(df_filtrado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cidade'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_agrupado\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m df_agrupado \u001b[38;5;241m=\u001b[39m \u001b[43magrupar_por_cidade_e_calcular_media_idade\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_agrupado)\n",
      "Cell \u001b[1;32mIn[35], line 12\u001b[0m, in \u001b[0;36magrupar_por_cidade_e_calcular_media_idade\u001b[1;34m(json_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(data)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Agrupar por cidade e calcular a média da idade\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df_agrupado \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcidade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midade\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_agrupado\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:7718\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7713\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7715\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7716\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7717\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7724\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7726\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cidade'"
     ]
    }
   ],
   "source": [
    "def agrupar_por_cidade_e_calcular_media_idade(json_data):\n",
    "    \"\"\"\n",
    "    Função para agrupar os clientes por cidade e calcular a média de idade por cidade.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para um DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Agrupar por cidade e calcular a média da idade\n",
    "    df_agrupado = df.groupby('cidade')['idade'].mean().reset_index()\n",
    "    \n",
    "    return df_agrupado\n",
    "\n",
    "# Exemplo de uso\n",
    "df_agrupado = agrupar_por_cidade_e_calcular_media_idade(json_data)\n",
    "print(df_agrupado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_idade_clientes(json_data, idade_adicional):\n",
    "    \"\"\"\n",
    "    Função para adicionar uma idade adicional a todos os clientes.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para um DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Atualizar a idade de todos os clientes\n",
    "    df['idade'] = df['idade'] + idade_adicional\n",
    "    \n",
    "    # Converter de volta para JSON\n",
    "    return dataframe_para_json(df)\n",
    "\n",
    "# Exemplo de uso\n",
    "json_atualizado = atualizar_idade_clientes(json_data, 2)\n",
    "print(json_atualizado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id_cliente'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_61372\\1672925136.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m compras_data = '''\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_61372\\1672925136.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(clientes_json, compras_json)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mdf_clientes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclientes_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mdf_compras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompras_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Mesclar os DataFrames com base no id_cliente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mdf_merged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_clientes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_compras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'id_cliente'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_merged\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 107\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m         (\n\u001b[0;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# to avoid incompatible dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1093\u001b[0m                             \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1836\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id_cliente'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\completerlib.py:146: UserWarning: using rootmodules_cache requires you to install the `pickleshare` library.\n",
      "  ip.db['rootmodules_cache'] = rootmodules_cache\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os \n",
    "\n",
    "compras_data = '''\n",
    "{\n",
    "    \"compras\": [\n",
    "        {\"id_cliente\": 1, \"produto\": \"Notebook\", \"quantidade\": 1},\n",
    "        {\"id_cliente\": 2, \"produto\": \"Smartphone\", \"quantidade\": 2},\n",
    "        {\"id_cliente\": 3, \"produto\": \"Cadeira gamer\", \"quantidade\": 1}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "def mesclar_clientes_com_compras(clientes_json, compras_json):\n",
    "    \"\"\"\n",
    "    Função para mesclar os dados de clientes e compras em um único DataFrame.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    clientes_data = json.loads(clientes_json)\n",
    "    compras_data = json.loads(compras_json)\n",
    "    \n",
    "    # Converter ambos os JSONs para DataFrames\n",
    "    df_clientes = pd.json_normalize(clientes_data)\n",
    "    df_compras = pd.json_normalize(compras_data)\n",
    "    \n",
    "    # Mesclar os DataFrames com base no id_cliente\n",
    "    df_merged = pd.merge(df_clientes, df_compras, left_on='id', right_on='id_cliente', how='inner')\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "# Exemplo de uso\n",
    "df_mesclado = mesclar_clientes_com_compras(json_data, compras_data)\n",
    "print(df_mesclado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 32\u001b[0m\n\u001b[0;32m     20\u001b[0m vendas_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m{\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvendas\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m \u001b[43mfiltrar_vendas_por_mes_e_valor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvendas_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m02\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_filtrado)\n",
      "Cell \u001b[1;32mIn[38], line 15\u001b[0m, in \u001b[0;36mfiltrar_vendas_por_mes_e_valor\u001b[1;34m(json_data, mes, valor_minimo)\u001b[0m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(data)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Filtrar os dados de vendas por mês e valor mínimo\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df_filtrado \u001b[38;5;241m=\u001b[39m df[(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(mes)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m valor_minimo)]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_filtrado\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def filtrar_vendas_por_mes_e_valor(json_data, mes, valor_minimo):\n",
    "    \"\"\"\n",
    "    Função para filtrar as vendas com base no mês e valor mínimo.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para um DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Filtrar os dados de vendas por mês e valor mínimo\n",
    "    df_filtrado = df[(df['data'].str.contains(mes)) & (df['valor'] >= valor_minimo)]\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "# Exemplo de dados JSON de vendas\n",
    "vendas_data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"id\": 1, \"produto\": \"Laptop\", \"valor\": 3500, \"data\": \"2025-01-15\"},\n",
    "        {\"id\": 2, \"produto\": \"Smartphone\", \"valor\": 1500, \"data\": \"2025-02-10\"},\n",
    "        {\"id\": 3, \"produto\": \"Fones de ouvido\", \"valor\": 200, \"data\": \"2025-02-15\"},\n",
    "        {\"id\": 4, \"produto\": \"Cadeira gamer\", \"valor\": 1200, \"data\": \"2025-02-20\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "df_filtrado = filtrar_vendas_por_mes_e_valor(vendas_data, \"02\", 1000)\n",
    "print(df_filtrado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: '/Python_Data_Engineer_new'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Diretorio com arquivos JSON (você precisa criar e colocar seus arquivos JSON)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m diretorio \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Python_Data_Engineer_new\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Exemplo de caminho\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df_completo \u001b[38;5;241m=\u001b[39m \u001b[43mcarregar_multipos_arquivos_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiretorio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_completo\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[41], line 13\u001b[0m, in \u001b[0;36mcarregar_multipos_arquivos_json\u001b[1;34m(diretorio)\u001b[0m\n\u001b[0;32m     10\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Percorrer todos os arquivos no diretório\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arquivo \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiretorio\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arquivo\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     15\u001b[0m         caminho_arquivo \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(diretorio, arquivo)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema não pode encontrar o caminho especificado: '/Python_Data_Engineer_new'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "def carregar_multipos_arquivos_json(diretorio):\n",
    "    \"\"\"\n",
    "    Função para carregar múltiplos arquivos JSON de um diretório e combinar em um único DataFrame.\n",
    "    \"\"\"\n",
    "    # Lista para armazenar os DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Percorrer todos os arquivos no diretório\n",
    "    for arquivo in os.listdir(diretorio):\n",
    "        if arquivo.endswith('.json'):\n",
    "            caminho_arquivo = os.path.join(diretorio, arquivo)\n",
    "            \n",
    "            # Abrir e carregar o arquivo JSON\n",
    "            with open(caminho_arquivo, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            # Converter JSON para DataFrame\n",
    "            df = pd.json_normalize(data)\n",
    "            dfs.append(df)\n",
    "    \n",
    "    # Combinar todos os DataFrames em um único\n",
    "    df_completo = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return df_completo\n",
    "\n",
    "# Exemplo de uso\n",
    "# Diretorio com arquivos JSON (você precisa criar e colocar seus arquivos JSON)\n",
    "diretorio = 'Python_Data_Engineer_new'  # Exemplo de caminho\n",
    "df_completo = carregar_multipos_arquivos_json(diretorio)\n",
    "print(df_completo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'produto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 34\u001b[0m\n\u001b[0;32m     21\u001b[0m vendas_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m{\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvendas\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mdividir_por_produto_e_salvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvendas_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 12\u001b[0m, in \u001b[0;36mdividir_por_produto_e_salvar\u001b[1;34m(json_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(data)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Dividir os dados por produto\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m grupos \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Salvar os dados de cada grupo em arquivos JSON separados\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m produto, grupo \u001b[38;5;129;01min\u001b[39;00m grupos:\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:7718\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7713\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7715\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7716\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7717\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7724\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7726\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\walla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'produto'"
     ]
    }
   ],
   "source": [
    "def dividir_por_produto_e_salvar(json_data):\n",
    "    \"\"\"\n",
    "    Função para dividir os dados JSON de vendas por produto e salvar em arquivos JSON separados.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Dividir os dados por produto\n",
    "    grupos = df.groupby('produto')\n",
    "    \n",
    "    # Salvar os dados de cada grupo em arquivos JSON separados\n",
    "    for produto, grupo in grupos:\n",
    "        arquivo_saida = f\"{produto.replace(' ', '_').lower()}.json\"\n",
    "        grupo.to_json(arquivo_saida, orient='records', lines=True)\n",
    "        print(f\"Arquivo salvo: {arquivo_saida}\")\n",
    "\n",
    "# Exemplo de dados JSON de vendas\n",
    "vendas_data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"id\": 1, \"produto\": \"Laptop\", \"valor\": 3500, \"data\": \"2025-01-15\"},\n",
    "        {\"id\": 2, \"produto\": \"Smartphone\", \"valor\": 1500, \"data\": \"2025-02-10\"},\n",
    "        {\"id\": 3, \"produto\": \"Fones de ouvido\", \"valor\": 200, \"data\": \"2025-02-15\"},\n",
    "        {\"id\": 4, \"produto\": \"Cadeira gamer\", \"valor\": 1200, \"data\": \"2025-02-20\"},\n",
    "        {\"id\": 5, \"produto\": \"Smartphone\", \"valor\": 1600, \"data\": \"2025-03-01\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "dividir_por_produto_e_salvar(vendas_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_lucro_e_imposto(json_data, custo_produto, taxa_imposto):\n",
    "    \"\"\"\n",
    "    Função para calcular o lucro (valor - custo) e o valor do imposto em cada venda.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para um DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Calcular lucro (valor da venda - custo do produto)\n",
    "    df['lucro'] = df['valor'] - custo_produto\n",
    "    \n",
    "    # Calcular o imposto (lucro * taxa de imposto)\n",
    "    df['imposto'] = df['lucro'] * (taxa_imposto / 100)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Exemplo de dados JSON de vendas\n",
    "vendas_data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"id\": 1, \"produto\": \"Laptop\", \"valor\": 3500, \"data\": \"2025-01-15\"},\n",
    "        {\"id\": 2, \"produto\": \"Smartphone\", \"valor\": 1500, \"data\": \"2025-02-10\"},\n",
    "        {\"id\": 3, \"produto\": \"Fones de ouvido\", \"valor\": 200, \"data\": \"2025-02-15\"},\n",
    "        {\"id\": 4, \"produto\": \"Cadeira gamer\", \"valor\": 1200, \"data\": \"2025-02-20\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "df_com_lucro_imposto = calcular_lucro_e_imposto(vendas_data, custo_produto=1000, taxa_imposto=10)\n",
    "print(df_com_lucro_imposto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_de_vendas(json_data):\n",
    "    \"\"\"\n",
    "    Função para calcular as métricas de desempenho de vendas, como total, média e produto mais vendido.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para um DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Calcular total de vendas\n",
    "    total_vendas = df['valor'].sum()\n",
    "    \n",
    "    # Calcular valor médio das vendas\n",
    "    media_vendas = df['valor'].mean()\n",
    "    \n",
    "    # Encontrar o produto mais vendido\n",
    "    produto_mais_vendido = df.groupby('produto')['valor'].sum().idxmax()\n",
    "    \n",
    "    return total_vendas, media_vendas, produto_mais_vendido\n",
    "\n",
    "# Exemplo de uso\n",
    "total, media, produto_mais_vendido = calcular_metricas_de_vendas(vendas_data)\n",
    "print(f\"Total de Vendas: {total}\")\n",
    "print(f\"Valor Médio das Vendas: {media}\")\n",
    "print(f\"Produto Mais Vendido: {produto_mais_vendido}\")\n",
    "def salvar_em_diferentes_formatos(df, nome_arquivo_base):\n",
    "    \"\"\"\n",
    "    Função para salvar o DataFrame em formatos diferentes (JSON, CSV, Excel).\n",
    "    \"\"\"\n",
    "    # Salvar como JSON\n",
    "    df.to_json(f'{nome_arquivo_base}.json', orient='records', lines=True)\n",
    "    print(f\"Arquivo JSON salvo: {nome_arquivo_base}.json\")\n",
    "    \n",
    "    # Salvar como CSV\n",
    "    df.to_csv(f'{nome_arquivo_base}.csv', index=False)\n",
    "    print(f\"Arquivo CSV salvo: {nome_arquivo_base}.csv\")\n",
    "    \n",
    "    # Salvar como Excel\n",
    "    df.to_excel(f'{nome_arquivo_base}.xlsx', index=False)\n",
    "    print(f\"Arquivo Excel salvo: {nome_arquivo_base}.xlsx\")\n",
    "\n",
    "# Exemplo de uso\n",
    "salvar_em_diferentes_formatos(df_com_lucro_imposto, 'vendas_com_lucro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def analisar_vendas_comissao(json_data):\n",
    "    \"\"\"\n",
    "    Função para calcular comissões totais por vendedor, total de vendas por categoria e valor médio por transação.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Calcular comissão total por vendedor\n",
    "    df['comissao_total'] = df['quantidade'] * df['preco_unitario'] * df['comissao']\n",
    "    \n",
    "    # Calcular total de vendas por categoria\n",
    "    total_vendas_categoria = df.groupby('categoria')['quantidade'].sum().reset_index(name='total_vendas')\n",
    "    \n",
    "    # Calcular valor médio de cada transação\n",
    "    valor_medio_transacao = df.groupby('id_transacao')['total'].mean().reset_index(name='valor_medio')\n",
    "    \n",
    "    return df[['id_vendedor', 'comissao_total']], total_vendas_categoria, valor_medio_transacao\n",
    "\n",
    "# Exemplo de dados JSON de vendas\n",
    "vendas_data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"id_transacao\": 1, \"id_vendedor\": 101, \"categoria\": \"Eletrônicos\", \"quantidade\": 2, \"preco_unitario\": 1500, \"comissao\": 0.1, \"total\": 3000},\n",
    "        {\"id_transacao\": 2, \"id_vendedor\": 102, \"categoria\": \"Móveis\", \"quantidade\": 1, \"preco_unitario\": 1200, \"comissao\": 0.08, \"total\": 1200},\n",
    "        {\"id_transacao\": 3, \"id_vendedor\": 101, \"categoria\": \"Eletrônicos\", \"quantidade\": 1, \"preco_unitario\": 1500, \"comissao\": 0.1, \"total\": 1500},\n",
    "        {\"id_transacao\": 4, \"id_vendedor\": 103, \"categoria\": \"Eletrônicos\", \"quantidade\": 3, \"preco_unitario\": 700, \"comissao\": 0.12, \"total\": 2100}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "comissao_vendedores, vendas_categoria, transacoes_media = analisar_vendas_comissao(vendas_data)\n",
    "\n",
    "print(\"Comissão total por vendedor:\")\n",
    "print(comissao_vendedores)\n",
    "\n",
    "print(\"\\nTotal de vendas por categoria:\")\n",
    "print(vendas_categoria)\n",
    "\n",
    "print(\"\\nValor médio por transação:\")\n",
    "print(transacoes_media)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def analisar_vendas_comissao(json_data):\n",
    "    \"\"\"\n",
    "    Função para calcular comissões totais por vendedor, total de vendas por categoria e valor médio por transação.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Calcular comissão total por vendedor\n",
    "    df['comissao_total'] = df['quantidade'] * df['preco_unitario'] * df['comissao']\n",
    "    \n",
    "    # Calcular total de vendas por categoria\n",
    "    total_vendas_categoria = df.groupby('categoria')['quantidade'].sum().reset_index(name='total_vendas')\n",
    "    \n",
    "    # Calcular valor médio de cada transação\n",
    "    valor_medio_transacao = df.groupby('id_transacao')['total'].mean().reset_index(name='valor_medio')\n",
    "    \n",
    "    return df[['id_vendedor', 'comissao_total']], total_vendas_categoria, valor_medio_transacao\n",
    "\n",
    "# Exemplo de dados JSON de vendas\n",
    "vendas_data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"id_transacao\": 1, \"id_vendedor\": 101, \"categoria\": \"Eletrônicos\", \"quantidade\": 2, \"preco_unitario\": 1500, \"comissao\": 0.1, \"total\": 3000},\n",
    "        {\"id_transacao\": 2, \"id_vendedor\": 102, \"categoria\": \"Móveis\", \"quantidade\": 1, \"preco_unitario\": 1200, \"comissao\": 0.08, \"total\": 1200},\n",
    "        {\"id_transacao\": 3, \"id_vendedor\": 101, \"categoria\": \"Eletrônicos\", \"quantidade\": 1, \"preco_unitario\": 1500, \"comissao\": 0.1, \"total\": 1500},\n",
    "        {\"id_transacao\": 4, \"id_vendedor\": 103, \"categoria\": \"Eletrônicos\", \"quantidade\": 3, \"preco_unitario\": 700, \"comissao\": 0.12, \"total\": 2100}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "comissao_vendedores, vendas_categoria, transacoes_media = analisar_vendas_comissao(vendas_data)\n",
    "\n",
    "print(\"Comissão total por vendedor:\")\n",
    "print(comissao_vendedores)\n",
    "\n",
    "print(\"\\nTotal de vendas por categoria:\")\n",
    "print(vendas_categoria)\n",
    "\n",
    "print(\"\\nValor médio por transação:\")\n",
    "print(transacoes_media)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_dados_usuarios(json_data):\n",
    "    \"\"\"\n",
    "    Função para limpar e transformar dados de usuários: remover registros inválidos, preencher valores ausentes.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Preencher valores ausentes com valores padrão (exemplo: 0 para id_usuario, 'Desconhecido' para nome)\n",
    "    df['id_usuario'].fillna(0, inplace=True)\n",
    "    df['nome'].fillna('Desconhecido', inplace=True)\n",
    "    \n",
    "    # Converter a coluna 'data_nascimento' para tipo datetime, e preencher valores inválidos com 'unknown'\n",
    "    df['data_nascimento'] = pd.to_datetime(df['data_nascimento'], errors='coerce')\n",
    "    df['data_nascimento'].fillna('unknown', inplace=True)\n",
    "    \n",
    "    # Remover registros com IDs de usuário faltando\n",
    "    df = df[df['id_usuario'] != 0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Exemplo de dados JSON de usuários\n",
    "usuarios_data = '''\n",
    "{\n",
    "    \"usuarios\": [\n",
    "        {\"id_usuario\": 101, \"nome\": \"João\", \"data_nascimento\": \"1990-05-15\", \"email\": \"joao@email.com\"},\n",
    "        {\"id_usuario\": null, \"nome\": \"Maria\", \"data_nascimento\": \"1985-03-22\", \"email\": \"maria@email.com\"},\n",
    "        {\"id_usuario\": 103, \"nome\": null, \"data_nascimento\": \"invalid_date\", \"email\": \"carlos@email.com\"},\n",
    "        {\"id_usuario\": 104, \"nome\": \"Ana\", \"data_nascimento\": \"1992-07-30\", \"email\": \"ana@email.com\"}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "df_limpo = limpar_dados_usuarios(usuarios_data)\n",
    "print(df_limpo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prever_vendas(json_data):\n",
    "    \"\"\"\n",
    "    Função para prever vendas futuras com base em dados históricos de vendas.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Garantir que a coluna 'data' seja do tipo datetime\n",
    "    df['data'] = pd.to_datetime(df['data'])\n",
    "    \n",
    "    # Agrupar as vendas por data\n",
    "    df_agrupado = df.groupby('data')['total'].sum().reset_index()\n",
    "    \n",
    "    # Definir a série temporal como a coluna de vendas (total)\n",
    "    series = df_agrupado.set_index('data')['total']\n",
    "    \n",
    "    # Ajustar o modelo ARIMA\n",
    "    model = ARIMA(series, order=(5, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Prever as vendas para os próximos 7 dias\n",
    "    previsao = model_fit.forecast(steps=7)\n",
    "    \n",
    "    # Plotar as vendas históricas e a previsão\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(series, label='Vendas Históricas')\n",
    "    plt.plot(pd.date_range(series.index[-1], periods=8, freq='D')[1:], previsao, label='Previsão de Vendas', color='red')\n",
    "    plt.title('Previsão de Vendas para os Próximos 7 Dias')\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Vendas Totais')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return previsao\n",
    "\n",
    "# Exemplo de dados JSON de vendas\n",
    "vendas_data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"data\": \"2025-01-01\", \"total\": 1000},\n",
    "        {\"data\": \"2025-01-02\", \"total\": 1200},\n",
    "        {\"data\": \"2025-01-03\", \"total\": 1500},\n",
    "        {\"data\": \"2025-01-04\", \"total\": 1300},\n",
    "        {\"data\": \"2025-01-05\", \"total\": 1100},\n",
    "        {\"data\": \"2025-01-06\", \"total\": 1600},\n",
    "        {\"data\": \"2025-01-07\", \"total\": 1700}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "previsao = prever_vendas(vendas_data)\n",
    "print(f\"Previsão de vendas para os próximos 7 dias: {previsao}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def integrar_dados_api_com_json(json_data, api_url):\n",
    "    \"\"\"\n",
    "    Função para integrar dados JSON com dados externos de uma API.\n",
    "    \"\"\"\n",
    "    # Carregar os dados JSON\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    # Converter o JSON para DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Fazer uma requisição à API\n",
    "    response = requests.get(api_url)\n",
    "    dados_api = response.json()\n",
    "    \n",
    "    # Converter os dados da API em DataFrame\n",
    "    df_api = pd.json_normalize(dados_api)\n",
    "    \n",
    "    # Exemplo de integração: adicionar a coluna de preços ao DataFrame original\n",
    "    df['preco_externo'] = df_api['preco']  # Supondo que a API forneça o campo 'preco'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Exemplo de dados JSON de vendas\n",
    "vendas_data = '''\n",
    "{\n",
    "    \"vendas\": [\n",
    "        {\"id\": 1, \"produto\": \"Smartphone\", \"quantidade\": 2, \"total\": 3000},\n",
    "        {\"id\": 2, \"produto\": \"Laptop\", \"quantidade\": 1, \"total\": 2500}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Exemplo de uso\n",
    "# Supondo que a URL da API forneça o preço atual do produto\n",
    "api_url = \"https://api.exemplo.com/precos\"\n",
    "df_integrado = integrar_dados_api_com_json(vendas_data, api_url)\n",
    "print(df_integrado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
